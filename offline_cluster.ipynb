{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import pickle \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import impute_head_tail_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Read and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dir = '###YOUR_DIRECTORY###/ArgoverseDatasets/train/processed' # data processed by QCNet \n",
    "processed_file_names = [name for name in os.listdir(processed_dir) if\n",
    "                        os.path.isfile(os.path.join(processed_dir, name)) and\n",
    "                        name.endswith(('pkl', 'pickle'))]\n",
    "print('Numbers of file: {}'.format(len(processed_file_names)))\n",
    "\n",
    "num_historical_steps = 50\n",
    "\n",
    "all_trajectory = []\n",
    "         \n",
    "for i in tqdm(range(len(processed_file_names))):\n",
    "    process_path = os.path.join(processed_dir, processed_file_names[i])\n",
    "    with open(process_path, 'rb') as handle:\n",
    "        data = pickle.load(handle)\n",
    "\n",
    "    # imputation\n",
    "    trajectory = impute_head_tail_zeros(data['agent']['position'][:, :, :2])\n",
    "    theta = impute_head_tail_zeros(data['agent']['heading'][:, :, None])[:, :, 0]\n",
    "    \n",
    "    # normalization\n",
    "    origin = trajectory[:, num_historical_steps - 1, 0:2]\n",
    "    _theta = theta[:, num_historical_steps - 1]\n",
    "    cos, sin = _theta.cos(), _theta.sin()\n",
    "    rot_mat = _theta.new_zeros(data['agent']['num_nodes'], 2, 2)\n",
    "    rot_mat[:, 0, 0] = cos\n",
    "    rot_mat[:, 0, 1] = -sin\n",
    "    rot_mat[:, 1, 0] = sin\n",
    "    rot_mat[:, 1, 1] = cos\n",
    "    norm_trajectory = torch.bmm(trajectory - origin[:, :2].unsqueeze(1), rot_mat)\n",
    "\n",
    "    all_trajectory.append(norm_trajectory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(norm_trajectory)):\n",
    "#     plt.plot(norm_trajectory[i, :, 0], norm_trajectory[i, :, 1])\n",
    "# plt.axis('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trajectory_arr = torch.concat(all_trajectory)\n",
    "print(all_trajectory_arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrajectoryEncoder(nn.Module):\n",
    "    def __init__(self, C1, C2, H):\n",
    "        \"\"\"\n",
    "        Encoder with 1D CNN and LSTM.\n",
    "\n",
    "        Args:\n",
    "            C1 (int): Number of output channels for the first CNN layer\n",
    "            C2 (int): Number of output channels for the second CNN layer\n",
    "            H (int): Hidden size of the LSTM (bottleneck feature size)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.cnn1 = nn.Conv1d(2, C1, kernel_size=3, padding=1)  # Input channels = 2 (x, y)\n",
    "        self.cnn2 = nn.Conv1d(C1, C2, kernel_size=3, padding=1)\n",
    "        self.lstm = nn.LSTM(C2, H, num_layers=1, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, T, 2)\n",
    "        x = x.permute(0, 2, 1)  # (batch_size, 2, T) for Conv1d\n",
    "        x = F.relu(self.cnn1(x))  # (batch_size, C1, T)\n",
    "        x = F.relu(self.cnn2(x))  # (batch_size, C2, T)\n",
    "        x = x.permute(0, 2, 1)  # (batch_size, T, C2) for LSTM\n",
    "        _, (h_n, _) = self.lstm(x)  # h_n: (1, batch_size, H)\n",
    "        encoded_feature = h_n[0]  # (batch_size, H)\n",
    "        return encoded_feature\n",
    "\n",
    "class TrajectoryDecoder(nn.Module):\n",
    "    def __init__(self, H):\n",
    "        \"\"\"\n",
    "        Decoder with LSTM to reconstruct the trajectory.\n",
    "\n",
    "        Args:\n",
    "            H (int): Hidden size of the LSTM (matches encoder bottleneck)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(2, H, num_layers=1, batch_first=True)  # Input size = 2 (x, y)\n",
    "        self.linear = nn.Linear(H, 2)  # Map LSTM output to (x, y)\n",
    "\n",
    "    def forward(self, encoded_feature, decoder_input):\n",
    "        # encoded_feature: (batch_size, H)\n",
    "        # decoder_input: (batch_size, T, 2)\n",
    "        h_0 = encoded_feature.unsqueeze(0)  # (1, batch_size, H)\n",
    "        c_0 = torch.zeros_like(h_0)  # (1, batch_size, H)\n",
    "        output, _ = self.lstm(decoder_input, (h_0, c_0))  # (batch_size, T, H)\n",
    "        pred_traj = self.linear(output)  # (batch_size, T, 2)\n",
    "        return pred_traj\n",
    "\n",
    "class TrajectoryAutoencoder(nn.Module):\n",
    "    def __init__(self, C1, C2, H):\n",
    "        \"\"\"\n",
    "        Autoencoder combining encoder and decoder.\n",
    "\n",
    "        Args:\n",
    "            C1 (int): Channels for first CNN layer\n",
    "            C2 (int): Channels for second CNN layer\n",
    "            H (int): Hidden size (bottleneck feature dimension)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.encoder = TrajectoryEncoder(C1, C2, H)\n",
    "        self.decoder = TrajectoryDecoder(H)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, T, 2)\n",
    "        encoded_feature = self.encoder(x)\n",
    "        # Prepare decoder input with teacher forcing: [0, x[:-1]]\n",
    "        batch_size = x.size(0)\n",
    "        start_token = torch.zeros(batch_size, 1, 2, device=x.device)\n",
    "        decoder_input = torch.cat([start_token, x[:, :-1, :]], dim=1)  # (batch_size, T, 2)\n",
    "        pred_traj = self.decoder(encoded_feature, decoder_input)\n",
    "        return pred_traj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset for trajectories\n",
    "class TrajectoryDataset(Dataset):\n",
    "    def __init__(self, trajectories):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            trajectories (torch.Tensor): Tensor of shape [n, T, 2] containing all trajectories.\n",
    "        \"\"\"\n",
    "        self.trajectories = trajectories\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.trajectories)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.trajectories[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Train AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C1 = 16  # CNN channels\n",
    "C2 = 32  # CNN channels\n",
    "H = 64   # Bottleneck feature size\n",
    "batch_size = 1024\n",
    "epochs = 5\n",
    "learning_rate = 0.001\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Training with DataLoader\n",
    "# Validation is not performed for simplicity\n",
    "def train_autoencoder(trajectories, batch_size=32, epochs=50, C1=16, C2=32, H=64, lr=0.001):\n",
    "    \n",
    "    # Create dataset and dataloader\n",
    "    dataset = TrajectoryDataset(trajectories)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    \n",
    "    # Initialize model, loss, and optimizer\n",
    "    model = TrajectoryAutoencoder(C1, C2, H).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for batch_traj in dataloader:\n",
    "            batch_traj = batch_traj.to(device)  # Shape: [batch_size, T, 2]\n",
    "            \n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            pred_traj = model(batch_traj)\n",
    "            loss = criterion(pred_traj, batch_traj)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * batch_traj.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / len(dataset)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "trained_model = train_autoencoder(\n",
    "    all_trajectory_arr, \n",
    "    batch_size=batch_size, \n",
    "    epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Extract features\n",
    "trained_model.eval()\n",
    "encoded_features_list = []\n",
    "\n",
    "# Process data in batches\n",
    "with torch.no_grad(): \n",
    "    num_trajectories = all_trajectory_arr.shape[0]\n",
    "    for start_idx in tqdm(range(0, num_trajectories, batch_size)):\n",
    "        end_idx = min(start_idx + batch_size, num_trajectories)\n",
    "        batch_traj = all_trajectory_arr[start_idx:end_idx]  # Shape: (batch_size, sequence_length, feature_dim)\n",
    "        batch_traj = batch_traj.to(device)\n",
    "        batch_features = trained_model.encoder(batch_traj)  # Shape: (batch_size, H)\n",
    "        batch_features = batch_features.cpu().numpy()\n",
    "        encoded_features_list.append(batch_features)\n",
    "\n",
    "# Concatenate all features\n",
    "encoded_features = np.concatenate(encoded_features_list, axis=0)  # Shape: (num_trajectories, H)\n",
    "\n",
    "print(f\"Extracted features shape: {encoded_features.shape}\")\n",
    "\n",
    "# Hierarchical K-means (example with 2 levels)\n",
    "K1 = 5  # Number of clusters at level 1\n",
    "K2 = 5  # Number of clusters at level 2\n",
    "\n",
    "# Level 1 clustering\n",
    "kmeans_l1 = KMeans(n_clusters=K1, n_init='auto', random_state=42)\n",
    "labels_l1 = kmeans_l1.fit_predict(encoded_features)  # Shape: (num_samples,)\n",
    "\n",
    "# Level 2 clustering within each level 1 cluster\n",
    "# Initialize the global labels for the second hierarchy\n",
    "num_samples = len(encoded_features)\n",
    "global_labels_l2 = np.zeros(num_samples, dtype=int)  # Unified label array for level 2\n",
    "\n",
    "# Keep track of the starting label index for each level 1 cluster's subclusters\n",
    "label_offset = 0\n",
    "\n",
    "for i in range(K1):\n",
    "    # Extract features for the current level 1 cluster\n",
    "    cluster_mask = (labels_l1 == i)\n",
    "    cluster_features = encoded_features[cluster_mask]\n",
    "    cluster_size = len(cluster_features)\n",
    "    \n",
    "    if cluster_size > K2:\n",
    "        # Perform level 2 clustering\n",
    "        kmeans_l2 = KMeans(n_clusters=K2, n_init='auto', random_state=42)\n",
    "        sub_labels = kmeans_l2.fit_predict(cluster_features)  # Local labels: [0, K2-1]\n",
    "        \n",
    "        # Map local subcluster labels to global labels\n",
    "        # For cluster i, labels should be in range [label_offset, label_offset + K2 - 1]\n",
    "        global_sub_labels = sub_labels + label_offset\n",
    "        global_labels_l2[cluster_mask] = global_sub_labels\n",
    "    else:\n",
    "        # If too few points, assign a default label (use the first label in the range for this cluster)\n",
    "        global_labels_l2[cluster_mask] = label_offset\n",
    "    \n",
    "    # Update the label offset for the next level 1 cluster\n",
    "    label_offset += K2\n",
    "\n",
    "# Verify the label range\n",
    "print(f\"Level 1 labels range: {labels_l1.min()} to {labels_l1.max()}\")\n",
    "print(f\"Level 2 labels range: {global_labels_l2.min()} to {global_labels_l2.max()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(labels_l1), len(global_labels_l2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarchical_labels = torch.stack([\n",
    "    torch.tensor(labels_l1),\n",
    "    torch.tensor(global_labels_l2)\n",
    "], dim=-1)\n",
    "hierarchical_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Save files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dir = '###YOUR_DIRECTORY###/ArgoverseDatasets/train/processed' # data processed by QCNet \n",
    "processed_file_names = [name for name in os.listdir(processed_dir) if\n",
    "                        os.path.isfile(os.path.join(processed_dir, name)) and\n",
    "                        name.endswith(('pkl', 'pickle'))]\n",
    "print('Numbers of file: {}'.format(len(processed_file_names)))\n",
    "\n",
    "scene_cluster_dict = {}\n",
    "\n",
    "start_idx = 0\n",
    "for i in tqdm(range(len(processed_file_names))):\n",
    "    process_path = os.path.join(processed_dir, processed_file_names[i])\n",
    "    with open(process_path, 'rb') as handle:\n",
    "        data = pickle.load(handle)\n",
    "\n",
    "    end_idx = start_idx + data['agent']['num_nodes']\n",
    "    scenario_id = data['scenario_id']\n",
    "    scene_cluster_dict[scenario_id] = hierarchical_labels[start_idx:end_idx]\n",
    "    start_idx = end_idx\n",
    "\n",
    "assert start_idx == len(hierarchical_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_path = 'results/scene_cluster_dict.pt'\n",
    "torch.save(scene_cluster_dict, pt_path)\n",
    "\n",
    "print(f\"Saved scene_cluster_dict to {pt_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cluster dictionary\n",
    "# pt_path = 'results/scene_cluster_dict.pt'\n",
    "# loaded_dict = torch.load(pt_path, weights_only=True)\n",
    "# print(f\"Loaded scene_cluster_dict with {len(loaded_dict)} entries\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
